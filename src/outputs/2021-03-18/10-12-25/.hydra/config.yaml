device: cuda:2
tokenizer:
  path: ../input/tokenizer
  file: tokenizer
images:
  size: 224
dataframes:
  path: ../input/dataframes/
  file: valid.csv
  num_workers: 8
model:
  backbone: resnet34
  level: -1
  hidden_size: 128
  num_hidden_layers: 6
  num_attention_heads: 8
  max_len: 350
predict:
  batch_size: 1024
  model_path: logs/checkpoints/best.pth
  fp16: false
  score: true
  submit: false
  path: ../predicts/
